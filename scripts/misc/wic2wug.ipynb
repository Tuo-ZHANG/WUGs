{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zASMJ4H54r0-",
        "outputId": "bb2e3b39-5041-4999-c990-f7b8e1fd3f7e"
      },
      "outputs": [],
      "source": [
        "!wget https://pilehvar.github.io/wic/package/WiC_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNQkbcRaC6B5",
        "outputId": "ea3508ef-6f78-4f57-b623-b5f71d06a7b2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the current working directory\n",
        "cwd = os.getcwd()\n",
        "\n",
        "# Print the current working directory\n",
        "print(cwd)\n",
        "\n",
        "root_directory = cwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU7JiunOJINI"
      },
      "outputs": [],
      "source": [
        "dev = os.makedirs( root_directory + '/WIC/dev', exist_ok=True )\n",
        "train = os.makedirs( root_directory + '/WIC/train', exist_ok=True )\n",
        "test = os.makedirs( root_directory + '/WIC/test', exist_ok=True )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U21Til5c5CnA"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('WiC_dataset.zip', 'r') as WiC:\n",
        "   WiC.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9unNJtRB9NA"
      },
      "outputs": [],
      "source": [
        "df_dev = pd.read_csv(root_directory +\"/dev/dev.data.txt\", sep = '\\t', names=[\"lemma\", \"pos\", \"index\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n",
        "df_train = pd.read_csv(root_directory + \"/train/train.data.txt\", sep = '\\t', names=[\"lemma\", \"pos\", \"index\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n",
        "df_test = pd.read_csv(root_directory + \"/test/test.data.txt\", sep = '\\t', names=[\"lemma\", \"pos\", \"index\", \"sent1\", \"sent2\"], encoding = 'UTF-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLnXTxNcsLem"
      },
      "outputs": [],
      "source": [
        "dev_label= pd.read_csv(root_directory + \"/dev/dev.gold.txt\", sep = '\\t', names = ['judgment'], encoding = 'UTF-8')\n",
        "train_label= pd.read_csv(root_directory + \"/train/train.gold.txt\", sep = '\\t', names = ['judgment'], encoding = 'UTF-8')\n",
        "test_label= pd.read_csv(root_directory + \"/test/test.gold.txt\", sep = '\\t', names = ['judgment'], encoding = 'UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UShtKK95Sdo"
      },
      "outputs": [],
      "source": [
        "x= df_dev['index'].tolist()\n",
        "y = df_train['index'].tolist()\n",
        "z = df_test['index'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLI1oPkw1Rii"
      },
      "outputs": [],
      "source": [
        "df_dash = df_dev[['lemma', 'sent1', 'sent2']]\n",
        "df_dash1 = df_train[['lemma', 'sent1', 'sent2']]\n",
        "df_dash2 = df_test[['lemma', 'sent1', 'sent2']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ANHu2jj1YZ8"
      },
      "outputs": [],
      "source": [
        "df1 = df_dash[['lemma', 'sent1']]\n",
        "df1.columns =  ['word', 'sent']\n",
        "df1[\"index\"] = df1.groupby(\"word\").cumcount()*2\n",
        "\n",
        "dfone = df_dash1[['lemma', 'sent1']]\n",
        "dfone.columns =  ['word', 'sent']\n",
        "dfone[\"index\"] = dfone.groupby(\"word\").cumcount()*2\n",
        "\n",
        "dfein = df_dash2[['lemma', 'sent1']]\n",
        "dfein.columns =  ['word', 'sent']\n",
        "dfein[\"index\"] = dfein.groupby(\"word\").cumcount()*2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ENUewpV5lH-"
      },
      "outputs": [],
      "source": [
        "df2 =  df_dash[['lemma', 'sent2']]\n",
        "df2.columns =  ['word', 'sent']\n",
        "df2[\"index\"] = df2.groupby(\"word\").cumcount()*2+1\n",
        "\n",
        "dftwo =  df_dash1[['lemma', 'sent2']]\n",
        "dftwo.columns =  ['word', 'sent']\n",
        "dftwo[\"index\"] = dftwo.groupby(\"word\").cumcount()*2+1\n",
        "\n",
        "dfdu =  df_dash2[['lemma', 'sent2']]\n",
        "dfdu.columns =  ['word', 'sent']\n",
        "dfdu[\"index\"] = dfdu.groupby(\"word\").cumcount()*2+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npdDVwrR5w_5"
      },
      "outputs": [],
      "source": [
        "df_final_dev = pd.concat([df1, df2])\n",
        "df_final_dev = df_final_dev.sort_values(by = ['word', 'index'], ascending = [True, True]) \n",
        "\n",
        "df_final_train = pd.concat([dfone, dftwo])\n",
        "df_final_train = df_final_train.sort_values(by = ['word', 'index'], ascending = [True, True])\n",
        "\n",
        "df_final_test = pd.concat([dfein, dfdu])\n",
        "df_final_test = df_final_test.sort_values(by = ['word', 'index'], ascending = [True, True])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64T1JBGB6BGP"
      },
      "outputs": [],
      "source": [
        "df_final_dev[\"identifier\"] = df_final_dev[\"word\"]+\"-\"+df_final_dev[\"index\"].astype(str)\n",
        "df_final_train[\"identifier\"] = df_final_train[\"word\"]+\"-\"+df_final_train[\"index\"].astype(str)\n",
        "df_final_test[\"identifier\"] = df_final_test[\"word\"]+\"-\"+df_final_test[\"index\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlOUbrv86eCw"
      },
      "outputs": [],
      "source": [
        "df_odd = df_final_dev[1::2]\n",
        "df_odd.columns = [\"word2\", \"sent2\", \"index2\", \"identifier2\"]\n",
        "df_even = df_final_dev[::2]\n",
        "df_even.columns = [\"word1\", \"sent1\", \"index1\", \"identifier1\"]\n",
        "df_final_dev = pd.concat([df_even, df_odd], axis=1)\n",
        "\n",
        "df_odd1 = df_final_train[1::2]\n",
        "df_odd1.columns = [\"word2\", \"sent2\", \"index2\", \"identifier2\"]\n",
        "df_even1 = df_final_train[::2]\n",
        "df_even1.columns = [\"word1\", \"sent1\", \"index1\", \"identifier1\"]\n",
        "df_final_train = pd.concat([df_even1, df_odd1], axis=1)\n",
        "\n",
        "df_odd2 = df_final_test[1::2]\n",
        "df_odd2.columns = [\"word2\", \"sent2\", \"index2\", \"identifier2\"]\n",
        "df_even2 = df_final_test[::2]\n",
        "df_even2.columns = [\"word1\", \"sent1\", \"index1\", \"identifier1\"]\n",
        "df_final_test = pd.concat([df_even2, df_odd2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr-ckvAc6q6y"
      },
      "outputs": [],
      "source": [
        "df_final_dev = df_final_dev[[\"word2\", \"sent2\", \"identifier2\", \"sent1\", \"identifier1\", 'index1', 'index2']]\n",
        "df_final_dev = df_final_dev.rename(columns={\"word2\":\"lemma\"})\n",
        "\n",
        "df_final_train = df_final_train[[\"word2\", \"sent2\", \"identifier2\", \"sent1\", \"identifier1\", 'index1', 'index2']]\n",
        "df_final_train = df_final_train.rename(columns={\"word2\":\"lemma\"})\n",
        "\n",
        "df_final_test = df_final_test[[\"word2\", \"sent2\", \"identifier2\", \"sent1\", \"identifier1\", 'index1', 'index2']]\n",
        "df_final_test = df_final_test.rename(columns={\"word2\":\"lemma\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOw5QTJR63HD"
      },
      "outputs": [],
      "source": [
        "df_final_dev[\"judgment\"] = dev_label[\"judgment\"].values.tolist()\n",
        "df_final_train[\"judgment\"] = train_label[\"judgment\"].values.tolist()\n",
        "df_final_test[\"judgment\"] = test_label[\"judgment\"].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ocKdC-Z7OXC"
      },
      "outputs": [],
      "source": [
        "df_final_dev = df_final_dev[['lemma', 'identifier2', 'identifier1', 'judgment']]\n",
        "df_final_train = df_final_train[['lemma', 'identifier2', 'identifier1', 'judgment']]\n",
        "df_final_test = df_final_test[['lemma', 'identifier2', 'identifier1', 'judgment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5-qiLq37jzm"
      },
      "outputs": [],
      "source": [
        "df_final_dev[\"annotator\"] = \"gold\"\n",
        "df_final_dev['comment'] = \" \"\n",
        "df_final_train[\"annotator\"] = \"gold\"\n",
        "df_final_train['comment'] = \" \"\n",
        "df_final_test[\"annotator\"] = \"gold\"\n",
        "df_final_test['comment'] = \" \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BW6UdCn7snM"
      },
      "outputs": [],
      "source": [
        "df_final_dev = df_final_dev[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\"]]\n",
        "df_final_train = df_final_train[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\"]]\n",
        "df_final_test = df_final_test[[\"identifier1\", \"identifier2\", \"annotator\", \"judgment\", \"comment\", \"lemma\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlq5vTgr76Xe"
      },
      "outputs": [],
      "source": [
        "df_final_dev = df_final_dev.reset_index(drop =True)\n",
        "df_final_train = df_final_train.reset_index(drop =True)\n",
        "df_final_test = df_final_test.reset_index(drop =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfb8pIx_zyhW"
      },
      "outputs": [],
      "source": [
        "for i in list(df_final_dev[\"lemma\"].value_counts().index):\n",
        "        tmp_df = df_final_dev[df_final_dev[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists(root_directory + '/WIC/dev'+ \"/\"+i):\n",
        "            os.mkdir(root_directory + '/WIC/dev'+ \"/\"+i)\n",
        "        np.savetxt(root_directory + '/WIC/dev' +\"/\"+i+\"/judgments.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUgdxcquI_iu"
      },
      "outputs": [],
      "source": [
        "for i in list(df_final_train[\"lemma\"].value_counts().index):\n",
        "        tmp_df = df_final_train[df_final_train[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists(root_directory + '/WIC/train'+ \"/\"+i):\n",
        "            os.mkdir(root_directory + '/WIC/train'+ \"/\"+i)\n",
        "        np.savetxt(root_directory + '/WIC/train' +\"/\"+i+\"/judgments.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L26qNL7XKJyH"
      },
      "outputs": [],
      "source": [
        "for i in list(df_final_test[\"lemma\"].value_counts().index):\n",
        "        tmp_df = df_final_test[df_final_test[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists(root_directory + '/WIC/test'+ \"/\"+i):\n",
        "            os.mkdir(root_directory + '/WIC/test'+ \"/\"+i)\n",
        "        np.savetxt(root_directory + '/WIC/test' +\"/\"+i+\"/judgments.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViTntw-4GRaD"
      },
      "outputs": [],
      "source": [
        "ind1 = []\n",
        "ind2 = []\n",
        "for i in x:\n",
        "    ind1.append(i.split('-')[0])\n",
        "    ind2.append(i.split('-')[1])\n",
        "\n",
        "ind_1 = []\n",
        "ind_2 = []\n",
        "for i in y:\n",
        "    ind_1.append(i.split('-')[0])\n",
        "    ind_2.append(i.split('-')[1])\n",
        "\n",
        "indone = []\n",
        "indtwo = []\n",
        "for i in z:\n",
        "    indone.append(i.split('-')[0])\n",
        "    indtwo.append(i.split('-')[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqWbHmIGGzQU"
      },
      "outputs": [],
      "source": [
        "df_dev.loc[:,'ind1'] = ind1\n",
        "df_dev.loc[:,'ind2'] = ind2\n",
        "\n",
        "df_train.loc[:,'ind_1'] = ind_1\n",
        "df_train.loc[:,'ind_2'] = ind_2\n",
        "\n",
        "df_test.loc[:,'indone'] = indone\n",
        "df_test.loc[:,'indtwo'] = indtwo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUtnwQu9F8ZD"
      },
      "outputs": [],
      "source": [
        "df1 = df_dev[['lemma', 'pos', 'sent1', 'ind1']]\n",
        "df1.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df10 = df_train[['lemma', 'pos', 'sent1', 'ind_1']]\n",
        "df10.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df100 = df_test[['lemma', 'pos', 'sent1', 'indone']]\n",
        "df100.columns =  ['lemma','pos', 'context_tokenized','ind']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f_E_QijHH4X"
      },
      "outputs": [],
      "source": [
        "df2 = df_dev[['lemma', 'pos', 'sent2', 'ind2']]\n",
        "df2.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df20 = df_train[['lemma', 'pos', 'sent2', 'ind_2']]\n",
        "df20.columns =  ['lemma','pos', 'context_tokenized','ind']\n",
        "df200 = df_test[['lemma', 'pos', 'sent2', 'indtwo']]\n",
        "df200.columns =  ['lemma','pos', 'context_tokenized','ind']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4nAuBb7Kbmi"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses = pd.concat([df1, df2])\n",
        "df_final_dev_uses = df_final_dev_uses.sort_values(by = ['lemma'], ascending = True)\n",
        "df_final_train_uses = pd.concat([df10, df20])\n",
        "df_final_train_uses= df_final_train_uses.sort_values(by = ['lemma'], ascending = True)\n",
        "df_final_test_uses = pd.concat([df100, df200])\n",
        "df_final_test_uses = df_final_test_uses.sort_values(by = ['lemma'], ascending = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s47rUQm873_"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses = df_final_dev_uses.reset_index(drop =True)\n",
        "df_final_train_uses = df_final_train_uses.reset_index(drop =True)\n",
        "df_final_test_uses = df_final_test_uses.reset_index(drop =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unW1QgHvNMle"
      },
      "outputs": [],
      "source": [
        "def get_indice(sent, indice):\n",
        "  tag = ''\n",
        "  indice = int(indice)\n",
        "  tok = sent.split(\" \")\n",
        "  #print(tok)\n",
        "  for i in range(len(tok)):\n",
        "    if i == indice:\n",
        "      tag = tok[i]\n",
        "  return str(sent.find(tag))+\":\"+str(sent.find(tag)+len(tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsgDiCA4VfBM"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses[\"indexes_target_token\"] = df_final_dev_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)\n",
        "df_final_train_uses[\"indexes_target_token\"] = df_final_train_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)\n",
        "df_final_test_uses[\"indexes_target_token\"] = df_final_test_uses.apply(lambda x: get_indice(x.context_tokenized, x.ind), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdfdHVEMtid9"
      },
      "outputs": [],
      "source": [
        "def get_indices_of_sent(sentence):\n",
        "    return \"0:\"+str(len(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5jXzydPujr9"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses[\"indexes_target_sentence\"] = df_final_dev_uses[\"context_tokenized\"].apply(get_indices_of_sent)\n",
        "df_final_train_uses[\"indexes_target_sentence\"] = df_final_train_uses[\"context_tokenized\"].apply(get_indices_of_sent)\n",
        "df_final_test_uses[\"indexes_target_sentence\"] = df_final_test_uses[\"context_tokenized\"].apply(get_indices_of_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6_TKjfTu_Xz"
      },
      "outputs": [],
      "source": [
        "def get_len_tok(sentence):\n",
        "  return \"0:\"+str(len(sentence.split(\" \")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR4qpS2vumQ2"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses['indexes_target_sentence_tokenized'] = df_final_dev_uses[\"context_tokenized\"].apply(get_len_tok)\n",
        "df_final_train_uses['indexes_target_sentence_tokenized'] = df_final_train_uses[\"context_tokenized\"].apply(get_len_tok)\n",
        "df_final_test_uses['indexes_target_sentence_tokenized'] = df_final_test_uses[\"context_tokenized\"].apply(get_len_tok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxwyUqX0vS2t"
      },
      "outputs": [],
      "source": [
        "lem = ''\n",
        "def lemmatizr(sent):\n",
        "  doc = nlp(sent)\n",
        "  for i in doc:\n",
        "    lem += i.lemma_\n",
        "    return lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru8yyJVexlq1"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses['context_lemmatized'] = df_final_dev_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uEfkquuNi06"
      },
      "outputs": [],
      "source": [
        "df_final_train_uses['context_lemmatized'] = df_final_train_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))\n",
        "df_final_test_uses['context_lemmatized'] = df_final_test_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.lemma_ for w in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S76RLldcZ1k4"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses['context_pos'] = df_final_dev_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))\n",
        "df_final_train_uses['context_pos'] = df_final_train_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))\n",
        "df_final_test_uses['context_pos'] = df_final_test_uses[\"context_tokenized\"].apply(lambda row: \" \".join([w.pos_ for w in nlp(row)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLQGcdXCRbzU"
      },
      "outputs": [],
      "source": [
        "df_final_dev_uses['date'] = \" \"\n",
        "df_final_dev_uses['grouping'] = 1\n",
        "df_final_dev_uses['description'] = \" \"\n",
        "df_final_dev_uses['context'] = df_final_dev_uses['context_tokenized']\n",
        "df_final_dev_uses['identifier'] = \" \"\n",
        "df_final_dev_uses['indexes_target_token_tokenized'] = df_final_dev_uses['ind']\n",
        "\n",
        "df_final_train_uses['date'] = \" \"\n",
        "df_final_train_uses['grouping'] = 1\n",
        "df_final_train_uses['description'] = \" \"\n",
        "df_final_train_uses['context'] = df_final_train_uses['context_tokenized']\n",
        "df_final_train_uses['identifier'] = \" \"\n",
        "df_final_train_uses['indexes_target_token_tokenized'] = df_final_train_uses['ind']\n",
        "\n",
        "df_final_test_uses['date'] = \" \"\n",
        "df_final_test_uses['grouping'] = 1\n",
        "df_final_test_uses['description'] = \" \"\n",
        "df_final_test_uses['context'] = df_final_test_uses['context_tokenized']\n",
        "df_final_test_uses['identifier'] = \" \"\n",
        "df_final_test_uses['indexes_target_token_tokenized'] = df_final_test_uses['ind']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O9FfJ9yagcw"
      },
      "outputs": [],
      "source": [
        "final_df_dev = df_final_dev_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos']]\n",
        "final_df_train = df_final_train_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos']]\n",
        "final_df_test = df_final_test_uses[['lemma', 'pos', 'date', 'grouping', 'identifier', 'description', 'context', 'indexes_target_token', 'indexes_target_sentence', 'context_tokenized', 'indexes_target_token_tokenized', 'indexes_target_sentence_tokenized', 'context_lemmatized', 'context_pos']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdVI14vP1X2B"
      },
      "outputs": [],
      "source": [
        "for i in list(final_df_dev[\"lemma\"].value_counts().index):\n",
        "        tmp_df = final_df_dev[final_df_dev[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists(root_directory + '/WIC/dev'+\"/\"+i):\n",
        "            os.mkdir(root_directory + '/WIC/dev'+\"/\"+i)\n",
        "        np.savetxt(root_directory + '/WIC/dev'+\"/\"+i+\"/uses.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6Mv22TNP-sX"
      },
      "outputs": [],
      "source": [
        "for i in list(final_df_train[\"lemma\"].value_counts().index):\n",
        "        tmp_df = final_df_train[final_df_train[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists(root_directory + '/WIC/train'+\"/\"+i):\n",
        "            os.mkdir(root_directory + '/WIC/train'+\"/\"+i)\n",
        "        np.savetxt(root_directory + '/WIC/train'+\"/\"+i+\"/uses.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9NEgdWcP_BK"
      },
      "outputs": [],
      "source": [
        "for i in list(final_df_test[\"lemma\"].value_counts().index):\n",
        "        tmp_df = final_df_test[final_df_test[\"lemma\"]==i]\n",
        "        numpy_df = tmp_df.to_numpy()\n",
        "        header = list(tmp_df.columns)\n",
        "        numpy_df = np.vstack([header, numpy_df])\n",
        "        if not os.path.exists(root_directory + '/WIC/test'+\"/\"+i):\n",
        "            os.mkdir(root_directory + '/WIC/test'+\"/\"+i)\n",
        "        np.savetxt(root_directory + '/WIC/test'+\"/\"+i+\"/uses.csv\", numpy_df,fmt='%s', delimiter='\\t')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
